data_dir: "/var/lib/vector"

sources:
  otlp_logs:
    type: "opentelemetry"
    grpc:
      address: "0.0.0.0:4317"
    http:
      address: "0.0.0.0:4318"

transforms:
  my_transform_id:
    type: remap
    inputs: ["otlp_logs.logs"]
    drop_on_abort: true
    source: |
<<<<<<< HEAD
      if !is_string(.resources."service.name") { abort }
      if !is_string(.resources.environment)    { abort }
      if !is_string(.resources.type)    { abort }


      # Normalize as strings (infallible)
      .service_name     = to_string(.resources."service.name") ?? "unknown"
      .environment_name = to_string(.resources.environment)    ?? "unknown"
      .type = to_string(.resources.type)    ?? "unknown"


      # sanitize service_name and environment_name
      .service_name = replace(.service_name, r'[^a-zA-Z0-9._-]', "_")
      .environment_name = replace(.environment_name, r'[^a-zA-Z0-9._-]', "_")
      .type = replace(.type, r'[^a-zA-Z0-9._-]', "_")

      # Handle attributes with fallible assignments and defaults
      .message    = to_string(.attributes.message) ?? "no_message"
      .log_level  = to_string(.attributes.level) ?? "unknown"
      .timestamp  = to_string(.attributes.time) ?? "unknown"
    timezone: local
=======
      # Set required fields with defaults
      # .component_type = "application"
      # .environment_name = "prod"
      # .service_name = "healthcheck"
      .message = string!(.message)
      
      
      # Extract from OTLP resources if available
      if exists(.resources."service_name") {
        .service_name = string!(.resources."service_name")
      }
      if exists(.resources.environment_name) {
        .environment_name = string!(.resources.environment_name)
      }
      if exists(.resources.component_type) {
        .component_type = string!(.resources.component_type)
      }
      
      .timestamp = .observed_timestamp
>>>>>>> main

sinks:
  my_sink_id:
    type: kafka
    inputs:
      - my_transform_id
    bootstrap_servers: "${KAFKA_BROKERS}"
<<<<<<< HEAD
    topic: "logs.{{.type}}_{{.environment_name}}_{{.service_name}}"
=======
    topic: "logs.{{.environment_name}}_{{.component_type}}_{{.service_name}}"
>>>>>>> main
    compression: zstd
    encoding:
      codec: protobuf
      protobuf:
        message_type: logwise.vector.logs.VectorLogs
        desc_file: "/etc/vector/logwise-vector.desc"
    librdkafka_options:
      linger.ms: "100"
      batch.size: "2500000"
  

api:
  enabled: true
  address: "0.0.0.0:8686"